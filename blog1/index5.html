<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>魑魅魍魉</title>
  <meta name="author" content="niult">




  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="./favicon.png" rel="icon">

  <link href="./theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="./">魑魅魍魉</a></h1>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>


<ul class="main-navigation">
      <li >
        <a href="./category/00qi-ta.html">00.其他</a>
      </li>
      <li >
        <a href="./category/00qi-ta-2.html">00.其他2</a>
      </li>
      <li >
        <a href="./category/01chang-yong-gong-ju.html">01常用工具</a>
      </li>
      <li >
        <a href="./category/02gong-ju-shi-yong.html">02.工具使用</a>
      </li>
      <li >
        <a href="./category/02wo-ai-du-shu.html">02.我爱读书</a>
      </li>
      <li >
        <a href="./category/03chang-yong-ming-ling.html">03.常用命令</a>
      </li>
      <li >
        <a href="./category/03shen-du-xue-xi.html">03深度学习</a>
      </li>
      <li >
        <a href="./category/book-pydata.html">Book-pydata</a>
      </li>
      <li >
        <a href="./category/ji-chu-zhi-shi.html">基础知识</a>
      </li>
      <li >
        <a href="./category/ji-qi-xue-xi-shi-zhan.html">机器学习实战</a>
      </li>
      <li >
        <a href="./category/ling-ji-chu-ru-men-shen-du-xue-xi.html">零基础入门深度学习</a>
      </li>
      <li >
        <a href="./category/shen-du-xue-xi.html">深度学习</a>
      </li>
      <li >
        <a href="./category/tools.html">Tools</a>
      </li>
      <li >
        <a href="./category/tools-numpy.html">Tools-numpy</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div class="blog-index">
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/shi-fen-zhong-shang-shou-xgboost_jupyter.html">十分钟上手xgboost_jupyter</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="xgboost">xgboost<a class="anchor-link" href="#xgboost">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="参考网址">&#21442;&#32771;&#32593;&#22336;<a class="anchor-link" href="#参考网址">&#182;</a></h2><p>1 XGBoost参数调优完全指南（附Python代码） <a href="https://www.cnblogs.com/mfryf/p/6293814.html">https://www.cnblogs.com/mfryf/p/6293814.html</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="XGBoost的参数">XGBoost&#30340;&#21442;&#25968;<a class="anchor-link" href="#XGBoost的参数">&#182;</a></h1><p>XGBoost的作者把所有的参数分成了三类：<br>
1、通用参数：宏观函数控制。<br>
2、Booster参数：控制每一步的booster(tree/regression)。<br>
3、学习目标参数：控制训练目标的表现。<br>
在这里我会类比GBM来讲解，所以作为一种基础知识。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="通用参数">&#36890;&#29992;&#21442;&#25968;<a class="anchor-link" href="#通用参数">&#182;</a></h2><p>这些参数用来控制XGBoost的宏观功能。</p>
<h3 id="booster[默认gbtree]">booster[&#40664;&#35748;gbtree]<a class="anchor-link" href="#booster[默认gbtree]">&#182;</a></h3><p>选择每次迭代的模型，有两种选择：
gbtree：基于树的模型
gbliner：线性模型</p>
<h3 id="silent[默认0]">silent[&#40664;&#35748;0]<a class="anchor-link" href="#silent[默认0]">&#182;</a></h3><p>当这个参数值为1时，静默模式开启，不会输出任何信息。 一般这个参数就保持默认的0，因为这样能帮我们更好地理解模型。</p>
<h3 id="nthread[默认值为最大可能的线程数]">nthread[&#40664;&#35748;&#20540;&#20026;&#26368;&#22823;&#21487;&#33021;&#30340;&#32447;&#31243;&#25968;]<a class="anchor-link" href="#nthread[默认值为最大可能的线程数]">&#182;</a></h3><p>这个参数用来进行多线程控制，应当输入系统的核数。 如果你希望使用CPU全部的核，那就不要输入这个参数，算法会自动检测它。
还有两个参数，XGBoost会自动设置，目前你不用管它。接下来咱们一起看booster参数。</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="booster参数">booster&#21442;&#25968;<a class="anchor-link" href="#booster参数">&#182;</a></h2><p>尽管有两种booster可供选择，我这里只介绍tree booster，因为它的表现远远胜过linear booster，所以linear booster很少用到。</p>
<h3 id="eta[默认0.3]">eta[&#40664;&#35748;0.3]<a class="anchor-link" href="#eta[默认0.3]">&#182;</a></h3><p>和GBM中的 learning rate 参数类似。 通过减少每一步的权重，可以提高模型的鲁棒性。 典型值为0.01-0.2。</p>
<h3 id="min_child_weight[默认1]">min_child_weight[&#40664;&#35748;1]<a class="anchor-link" href="#min_child_weight[默认1]">&#182;</a></h3><p>决定最小叶子节点样本权重和。 和GBM的 min_child_leaf 参数类似，但不完全一样。XGBoost的这个参数是最小样本权重的和，而GBM参数是最小样本总数。 这个参数用于避免过拟合。当它的值较大时，可以避免模型学习到局部的特殊样本。 但是如果这个值过高，会导致欠拟合。这个参数需要使用CV来调整。</p>
<h2 id="max_depth[默认6]">max_depth[&#40664;&#35748;6]<a class="anchor-link" href="#max_depth[默认6]">&#182;</a></h2><p>和GBM中的参数相同，这个值为树的最大深度。 这个值也是用来避免过拟合的。max_depth越大，模型会学到更具体更局部的样本。 需要使用CV函数来进行调优。 典型值：3-10</p>
<h3 id="max_leaf_nodes">max_leaf_nodes<a class="anchor-link" href="#max_leaf_nodes">&#182;</a></h3><p>树上最大的节点或叶子的数量。 可以替代max_depth的作用。因为如果生成的是二叉树，一个深度为n的树最多生成n2个叶子。 如果定义了这个参数，GBM会忽略max_depth参数。</p>
<h3 id="gamma[默认0]">gamma[&#40664;&#35748;0]<a class="anchor-link" href="#gamma[默认0]">&#182;</a></h3><p>在节点分裂时，只有分裂后损失函数的值下降了，才会分裂这个节点。Gamma指定了节点分裂所需的最小损失函数下降值。 这个参数的值越大，算法越保守。这个参数的值和损失函数息息相关，所以是需要调整的。</p>
<h3 id="max_delta_step[默认0]">max_delta_step[&#40664;&#35748;0]<a class="anchor-link" href="#max_delta_step[默认0]">&#182;</a></h3><p>这参数限制每棵树权重改变的最大步长。如果这个参数的值为0，那就意味着没有约束。如果它被赋予了某个正值，那么它会让这个算法更加保守。 通常，这个参数不需要设置。但是当各类别的样本十分不平衡时，它对逻辑回归是很有帮助的。 这个参数一般用不到，但是你可以挖掘出来它更多的用处。</p>
<h3 id="subsample[默认1]">subsample[&#40664;&#35748;1]<a class="anchor-link" href="#subsample[默认1]">&#182;</a></h3><p>和GBM中的subsample参数一模一样。这个参数控制对于每棵树，随机采样的比例。 减小这个参数的值，算法会更加保守，避免过拟合。但是，如果这个值设置得过小，它可能会导致欠拟合。 典型值：0.5-1</p>
<h3 id="colsample_bytree[默认1]">colsample_bytree[&#40664;&#35748;1]<a class="anchor-link" href="#colsample_bytree[默认1]">&#182;</a></h3><p>和GBM里面的max_features参数类似。用来控制每棵随机采样的列数的占比(每一列是一个特征)。 典型值：0.5-1</p>
<h3 id="colsample_bylevel[默认1]">colsample_bylevel[&#40664;&#35748;1]<a class="anchor-link" href="#colsample_bylevel[默认1]">&#182;</a></h3><p>用来控制树的每一级的每一次分裂，对列数的采样的占比。 我个人一般不太用这个参数，因为subsample参数和colsample_bytree参数可以起到相同的作用。但是如果感兴趣，可以挖掘这个参数更多的用处。</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/shi-fen-zhong-shang-shou-xgboost_jupyter.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/shu-ju-index.html">数据index</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><p><a href="http:#pandas.pydata.org/pandas-docs/stable/10min.html#">来自官网十分钟教学</a> 
Pandas的主要数据结构：</p>
<p>DimensionsNameDescription1Series1D labeled homogeneously-typed array2DataFrameGeneral 2D labeled, size-mutable tabular structure with potentially heterogeneously-typed columns3PanelGeneral 3D labeled, also size-mutable array</p>
<h1>一、引入</h1>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>   <span class="c1">#数据分析，代码基于numpy</span>
<span class="kn">import</span> <span class="nn">numpy …</span></pre></div></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/shu-ju-index.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/stock_example.html">stock_Example</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/stock_example.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/sun-shi-han-shu.html">损失函数</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><p><a href="http://blog.csdn.net/u014595019/article/details/52562159">参考网址</a></p>
<h2>损失函数</h2>
<p>在之前的内容中，我们用的损失函数都是平方差函数，即 </p>
<p>$$C=\frac{1}{2}(a−y)^2$$</p>
<p>其中y是我们期望的输出，$a$为神经元的实际输出$a=\sigma(Wx+b)$。也就是说，当神经元的实际输出与我们的期望输出差距越大，代价就越高。想法非常的好，然而在实际应用中，我们知道参数的修正是与$\frac{\partial{C}}{\partial{W …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/sun-shi-han-shu.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/tensorflowyou-hua-qi-de-xuan-ze.html">tensorflow优化器的选择</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><p>在很多机器学习和深度学习的应用中，我们发现用的最多的优化器是 Adam，为什么呢？</p>
<p>下面是 TensorFlow 中的优化器， 
<a href="https://www.tensorflow.org/api_guides/python/train">https://www.tensorflow.org/api_guides/python/train</a>
<img alt="" src="https://github.com/1007530194/datas/blob/master/images/blog/study/others/28A308A65B43D79482C913803F349716.png"/></p>
<p>在 keras 中也有 SGD，RMSprop，Adagrad，Adadelta，Adam 等： 
<a href="https://keras.io/optimizers/">https://keras.io/optimizers/</a></p>
<p>我们可以发现除了常见的梯度下降，还有 Adadelta …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/tensorflowyou-hua-qi-de-xuan-ze.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/word2vec.html">word2vec</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Word2Vec-(Word-Embedding)">Word2Vec (Word Embedding)<a class="anchor-link" href="#Word2Vec-(Word-Embedding)">&#182;</a></h1><p>Implement Word2Vec algorithm to compute vector representations of words.
This example is using a small chunk of Wikipedia articles to train from.</p>
<p>More info: <a href="https://arxiv.org/pdf/1301.3781.pdf">Mikolov, Tomas et al. "Efficient Estimation of Word Representations in Vector Space.", 2013</a></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/word2vec.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/zhu-cheng-fen-fen-xi.html">主成分分析</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><p>转载请声明出处：<a href="http://blog.csdn.net/zhongkelee/article/details/44064401">http://blog.csdn.net/zhongkelee/article/details/44064401</a></p>
<h1><strong>一、PCA简介</strong></h1>
<h2><strong>1. 相关背景</strong></h2>
<p>上完陈恩红老师的《机器学习与知识发现》和季海波老师的《矩阵代数》两门课之后，颇有体会。最近在做主成分分析和奇异值分解方面的项目，所以记录一下心得体会。</p>
<p>在许多领域的研究与应用中，往往需要对反映事物的多个变量进行大量的观测，收集大量数据以便进行分析寻找规律。多变量大样本无疑会为研究和应用提供了丰富的信息，但也在一定程度上增加了数据采集的工作量，更重要的是在多数情况下，许多变量之间可能存在相关性，从而增加了问题分析的复杂性，同时对分析带来不便 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/zhu-cheng-fen-fen-xi.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/zui-xiao-er-cheng-fa.html">最小二乘法</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>最小二乘法</h1>
<p>我们从矩阵的角度来理解： 
首先我们给出一个矩阵中的定义： </p>
<p>$$R(A)={Ax|x∈R^n},A∈R^{n×n}$$</p>
<p>有了上面的定义之后，我们就可以写出最小二乘问题的矩阵形式： </p>
<p>$$∃b∉R(A),b∈R^n,\min_{x∈R^n}\parallel Ax−b\parallel _2 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/zui-xiao-er-cheng-fa.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/10k-meansju-lei.html">10.k-means聚类</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第 10 章 K-Means（K-均值）聚类算法</h1>
<h2>K-Means 算法</h2>
<p>聚类是一种无监督的学习, 它将相似的对象归到一个簇中, 将不相似对象归到不同簇中.<br/>
相似这一概念取决于所选择的相似度计算方法.<br/>
K-Means 是发现给定数据集的 K 个簇的聚类算法, 之所以称之为 <code>K-均值</code> 是因为它可以发现 K 个不同的簇, 且每个簇的中心采用簇中所含值的均值计算而成.<br/>
簇个数 K 是用户指定的, 每一个簇通过其质心（centroid）, 即簇中所有点的中心来描述.<br/>
聚类与分类算法的最大区别在于, 分类的目标类别已知 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/10k-meansju-lei.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/11apriori-guan-lian-fen-xi.html">11.Apriori-关联分析</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第 11 章 使用 Apriori 算法进行关联分析</h1>
<h2>关联分析</h2>
<p>关联分析是一种在大规模数据集中寻找有趣关系的任务。
这些关系可以有两种形式: 
<em> 频繁项集（frequent item sets）: 经常出现在一块的物品的集合。
</em> 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。</p>
<h2>相关术语</h2>
<ul>
<li>
<p>关联分析（关联规则学习): 从大规模数据集中寻找物品间的隐含关系被称作 <code>关联分析(associati analysis)</code> 或者 <code>关联规则学习（association rule learning …</code></p></li></ul></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/11apriori-guan-lian-fen-xi.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/12fp-growth-pin-fan-xiang-ji.html">12.FP-growth-频繁项集</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第12章 使用FP-growth算法来高效发现频繁项集</h1>
<h2>前言</h2>
<p>在 <a href="">第11章</a> 时我们已经介绍了用 <code>Apriori</code> 算法发现 <code>频繁项集</code> 与 <code>关联规则</code>。<br/>
本章将继续关注发现 <code>频繁项集</code> 这一任务，并使用 <code>FP-growth</code> 算法更有效的挖掘 <code>频繁项集</code>。</p>
<h2>FP-growth 算法简介</h2>
<ul>
<li>一种非常好的发现频繁项集算法。</li>
<li>基于Apriori算法构建,但是数据结构不同，使用叫做 <code>FP树</code> 的数据结构结构来存储集合。下面我们会介绍这种数据结构。</li>
</ul>
<h2>FP-growth 算法步骤</h2>
<ul>
<li>基于数据构建FP树 …</li></ul></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/12fp-growth-pin-fan-xiang-ji.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/13li-yong-pcalai-jian-hua-shu-ju.html">13.利用PCA来简化数据</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第13章 利用 PCA 来简化数据</h1>
<h2>降维技术</h2>
<blockquote>
<p>场景</p>
</blockquote>
<ul>
<li>我们正通过电视观看体育比赛，在电视的显示器上有一个球。</li>
<li>显示器大概包含了100万像素点，而球则可能是由较少的像素点组成，例如说一千个像素点。</li>
<li>人们实时的将显示器上的百万像素转换成为一个三维图像，该图像就给出运动场上球的位置。</li>
<li>在这个过程中，人们已经将百万像素点的数据，降至为三维。这个过程就称为<code>降维(dimensionality reduction)</code></li>
</ul>
<blockquote>
<p>数据显示 并非大规模特征下的唯一难题，对数据进行简化还有如下一系列的原因：</p>
</blockquote>
<ul>
<li>1) 使得数据集更容易使用</li>
<li>2) 降低很多算法的计算开销</li>
<li>3) 去除噪音</li>
<li>4 …</li></ul></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/13li-yong-pcalai-jian-hua-shu-ju.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/14li-yong-svdjian-hua-shu-ju.html">14.利用SVD简化数据</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第14章 利用SVD简化数据</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>SVD 概述</h2>
<div class="highlight"><pre><span></span>奇异值分解（SVD, Singular Value Decomposition）:
    提取信息的一种方法，可以把 SVD 看成是从噪声数据中抽取相关特征。从生物信息学到金融学，SVD 是提取信息的强大工具。
</pre></div>
<h2>SVD 场景</h2>
<blockquote>
<p>信息检索-隐性语义检索（Lstent Semantic Indexing, LSI）或 隐形语义分析（Latent Semantic Analysis, LSA）</p>
</blockquote>
<p>隐性语义索引 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/14li-yong-svdjian-hua-shu-ju.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/15da-shu-ju-yu-mapreduce.html">15.大数据与MapReduce</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第15章 大数据与MapReduce</h1>
<h2>大数据 概述</h2>
<p><code>大数据: 收集到的数据已经远远超出了我们的处理能力。</code></p>
<h2>大数据 场景</h2>
<div class="highlight"><pre><span></span>假如你为一家网络购物商店工作，很多用户访问该网站，其中有些人会购买商品，有些人则随意浏览后就离开。
对于你来说，可能很想识别那些有购物意愿的用户。
那么问题就来了，数据集可能会非常大，在单机上训练要运行好几天。
接下来：我们讲讲 MapRedece 如何来解决这样的问题
</pre></div>
<h2>MapRedece</h2>
<h3>Hadoop 概述</h3>
<div class="highlight"><pre><span></span>Hadoop 是 MapRedece 框架的一个免费开源实现。
MapReduce: 分布式的计算框架 …</pre></div></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/15da-shu-ju-yu-mapreduce.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/16tui-jian-xi-tong.html">16.推荐系统</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第16章 推荐系统</h1>
<h2>背景与挖掘目标</h2>
<p>随着互联网的快速发展，用户很难快速从海量信息中寻找到自己感兴趣的信息。因此诞生了：搜索引擎+推荐系统</p>
<p>本章节-推荐系统：</p>
<ol>
<li>帮助用户发现其感兴趣和可能感兴趣的信息。</li>
<li>让网站价值信息脱颖而出，得到广大用户的认可。</li>
<li>提高用户对网站的忠诚度和关注度，建立稳固用户群体。</li>
</ol>
<h2>分析方法与过程</h2>
<p>本案例的目标是对用户进行推荐，即以一定的方式将用户与物品（本次指网页）之间建立联系。</p>
<p>由于用户访问网站的数据记录很多，如果不对数据进行分类处理，对所有的记录直接采用推荐系统进行推荐，这样会存在一下问题。</p>
<ol>
<li>数据量太大意味着物品数与用户数很多，在模型构建用户与物品稀疏矩阵时，出现设备内存空间不够的情况，并且模型计算需要消耗大量的时间。</li>
<li>用户区别很大，不同的用户关注的信息不一样，因此 …</li></ol></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/16tui-jian-xi-tong.html">Read On &crarr;</a>
  </footer>
  		</article>
<div class="pagination">
    <a class="prev" href="./index6.html">&larr; Older</a>

    <a class="next" href="./index4.html">Newer &rarr;</a>
  <br />
</div></div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="./pages/2018/01/00-introduction-to-numpy.html">00-Introduction-to-NumPy</a>
      </li>
      <li class="post">
          <a href="./pages/2018/01/00-numpy.html">00-numpy</a>
      </li>
      <li class="post">
          <a href="./pages/2018/01/01-understanding-data-types.html">01-Understanding-Data-Types</a>
      </li>
      <li class="post">
          <a href="./pages/2018/01/02-the-basics-of-numpy-arrays.html">02-The-Basics-Of-NumPy-Arrays</a>
      </li>
      <li class="post">
          <a href="./pages/2018/01/03-computation-on-arrays-ufuncs.html">03-Computation-on-arrays-ufuncs</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="./category/00qi-ta.html">00.其他</a></li>
        <li><a href="./category/00qi-ta-2.html">00.其他2</a></li>
        <li><a href="./category/01chang-yong-gong-ju.html">01常用工具</a></li>
        <li><a href="./category/02gong-ju-shi-yong.html">02.工具使用</a></li>
        <li><a href="./category/02wo-ai-du-shu.html">02.我爱读书</a></li>
        <li><a href="./category/03chang-yong-ming-ling.html">03.常用命令</a></li>
        <li><a href="./category/03shen-du-xue-xi.html">03深度学习</a></li>
        <li><a href="./category/book-pydata.html">book-pydata</a></li>
        <li><a href="./category/ji-chu-zhi-shi.html">基础知识</a></li>
        <li><a href="./category/ji-qi-xue-xi-shi-zhan.html">机器学习实战</a></li>
        <li><a href="./category/ling-ji-chu-ru-men-shen-du-xue-xi.html">零基础入门深度学习</a></li>
        <li><a href="./category/shen-du-xue-xi.html">深度学习</a></li>
        <li><a href="./category/tools.html">tools</a></li>
        <li><a href="./category/tools-numpy.html">tools-numpy</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="./tag/python.html">python</a>,    <a href="./tag/numpy.html">numpy</a>,    <a href="./tag/gong-ju.html">工具</a>,    <a href="./tag/pip.html">pip</a>,    <a href="./tag/geng-xin-suo-you-mo-kuai.html">更新所有模块</a>,    <a href="./tag/tensorflowexample.html">TensorFlowExample</a>,    <a href="./tag/tensorflow.html">tensorflow</a>,    <a href="./tag/shen-du-xue-xi.html">深度学习</a>,    <a href="./tag/jupyter.html">jupyter</a>,    <a href="./tag/xun-huan-shen-jing-wang-luo.html">循环神经网络</a>,    <a href="./tag/pangrank.html">PangRank</a>,    <a href="./tag/mapreduce.html">MapReduce</a>,    <a href="./tag/book.html">book</a>,    <a href="./tag/pydata.html">pydata</a>,    <a href="./tag/pyhton.html">pyhton</a>,    <a href="./tag/xgboost.html">xgboost</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="#" target="_blank">You can add links in your config file</a></li>
            <li><a href="#" target="_blank">Another social link</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://getpelican.com/" target="_blank">pelican</a></li>
            <li><a href="http://python.org/" target="_blank">python</a></li>
            <li><a href="#" target="_blank">You can modify those links in your config file</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
        活到老，学到老，玩到老
    <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="./theme/js/modernizr-2.0.js"></script>
  <script src="./theme/js/ender.js"></script>
  <script src="./theme/js/octopress.js" type="text/javascript"></script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-127062347-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-127062347-1');
    ga('send', 'pageview');
</script>
</body>
</html>