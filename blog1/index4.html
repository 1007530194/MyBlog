<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>魑魅魍魉</title>
  <meta name="author" content="niult">




  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="./favicon.png" rel="icon">

  <link href="./theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="./">魑魅魍魉</a></h1>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>


<ul class="main-navigation">
      <li >
        <a href="./category/00qi-ta.html">00.其他</a>
      </li>
      <li >
        <a href="./category/00qi-ta-2.html">00.其他2</a>
      </li>
      <li >
        <a href="./category/01chang-yong-gong-ju.html">01常用工具</a>
      </li>
      <li >
        <a href="./category/02gong-ju-shi-yong.html">02.工具使用</a>
      </li>
      <li >
        <a href="./category/02wo-ai-du-shu.html">02.我爱读书</a>
      </li>
      <li >
        <a href="./category/03chang-yong-ming-ling.html">03.常用命令</a>
      </li>
      <li >
        <a href="./category/03shen-du-xue-xi.html">03深度学习</a>
      </li>
      <li >
        <a href="./category/book-pydata.html">Book-pydata</a>
      </li>
      <li >
        <a href="./category/ji-chu-zhi-shi.html">基础知识</a>
      </li>
      <li >
        <a href="./category/ji-qi-xue-xi-shi-zhan.html">机器学习实战</a>
      </li>
      <li >
        <a href="./category/shen-du-xue-xi.html">深度学习</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div class="blog-index">
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/shu-ju-index.html">数据index</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><p><a href="http:#pandas.pydata.org/pandas-docs/stable/10min.html#">来自官网十分钟教学</a> 
Pandas的主要数据结构：</p>
<p>DimensionsNameDescription1Series1D labeled homogeneously-typed array2DataFrameGeneral 2D labeled, size-mutable tabular structure with potentially heterogeneously-typed columns3PanelGeneral 3D labeled, also size-mutable array</p>
<h1>一、引入</h1>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>   <span class="c1">#数据分析，代码基于numpy</span>
<span class="kn">import</span> <span class="nn">numpy …</span></pre></div></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/shu-ju-index.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/stock_example.html">stock_Example</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/stock_example.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/sun-shi-han-shu.html">损失函数</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><p><a href="http://blog.csdn.net/u014595019/article/details/52562159">参考网址</a></p>
<h2>损失函数</h2>
<p>在之前的内容中，我们用的损失函数都是平方差函数，即 </p>
<p>$$C=\frac{1}{2}(a−y)^2$$</p>
<p>其中y是我们期望的输出，$a$为神经元的实际输出$a=\sigma(Wx+b)$。也就是说，当神经元的实际输出与我们的期望输出差距越大，代价就越高。想法非常的好，然而在实际应用中，我们知道参数的修正是与$\frac{\partial{C}}{\partial{W …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/sun-shi-han-shu.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/tensorflowyou-hua-qi-de-xuan-ze.html">tensorflow优化器的选择</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><p>在很多机器学习和深度学习的应用中，我们发现用的最多的优化器是 Adam，为什么呢？</p>
<p>下面是 TensorFlow 中的优化器， 
<a href="https://www.tensorflow.org/api_guides/python/train">https://www.tensorflow.org/api_guides/python/train</a>
<img alt="" src="https://github.com/1007530194/datas/blob/master/images/blog/study/others/28A308A65B43D79482C913803F349716.png"/></p>
<p>在 keras 中也有 SGD，RMSprop，Adagrad，Adadelta，Adam 等： 
<a href="https://keras.io/optimizers/">https://keras.io/optimizers/</a></p>
<p>我们可以发现除了常见的梯度下降，还有 Adadelta …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/tensorflowyou-hua-qi-de-xuan-ze.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/word2vec.html">word2vec</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Word2Vec-(Word-Embedding)">Word2Vec (Word Embedding)<a class="anchor-link" href="#Word2Vec-(Word-Embedding)">&#182;</a></h1><p>Implement Word2Vec algorithm to compute vector representations of words.
This example is using a small chunk of Wikipedia articles to train from.</p>
<p>More info: <a href="https://arxiv.org/pdf/1301.3781.pdf">Mikolov, Tomas et al. "Efficient Estimation of Word Representations in Vector Space.", 2013</a></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/word2vec.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/zhu-cheng-fen-fen-xi.html">主成分分析</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><p>转载请声明出处：<a href="http://blog.csdn.net/zhongkelee/article/details/44064401">http://blog.csdn.net/zhongkelee/article/details/44064401</a></p>
<h1><strong>一、PCA简介</strong></h1>
<h2><strong>1. 相关背景</strong></h2>
<p>上完陈恩红老师的《机器学习与知识发现》和季海波老师的《矩阵代数》两门课之后，颇有体会。最近在做主成分分析和奇异值分解方面的项目，所以记录一下心得体会。</p>
<p>在许多领域的研究与应用中，往往需要对反映事物的多个变量进行大量的观测，收集大量数据以便进行分析寻找规律。多变量大样本无疑会为研究和应用提供了丰富的信息，但也在一定程度上增加了数据采集的工作量，更重要的是在多数情况下，许多变量之间可能存在相关性，从而增加了问题分析的复杂性，同时对分析带来不便 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/zhu-cheng-fen-fen-xi.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/zui-xiao-er-cheng-fa.html">最小二乘法</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>最小二乘法</h1>
<p>我们从矩阵的角度来理解： 
首先我们给出一个矩阵中的定义： </p>
<p>$$R(A)={Ax|x∈R^n},A∈R^{n×n}$$</p>
<p>有了上面的定义之后，我们就可以写出最小二乘问题的矩阵形式： </p>
<p>$$∃b∉R(A),b∈R^n,\min_{x∈R^n}\parallel Ax−b\parallel _2 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/zui-xiao-er-cheng-fa.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/10k-meansju-lei.html">10.k-means聚类</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第 10 章 K-Means（K-均值）聚类算法</h1>
<h2>K-Means 算法</h2>
<p>聚类是一种无监督的学习, 它将相似的对象归到一个簇中, 将不相似对象归到不同簇中.<br/>
相似这一概念取决于所选择的相似度计算方法.<br/>
K-Means 是发现给定数据集的 K 个簇的聚类算法, 之所以称之为 <code>K-均值</code> 是因为它可以发现 K 个不同的簇, 且每个簇的中心采用簇中所含值的均值计算而成.<br/>
簇个数 K 是用户指定的, 每一个簇通过其质心（centroid）, 即簇中所有点的中心来描述.<br/>
聚类与分类算法的最大区别在于, 分类的目标类别已知 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/10k-meansju-lei.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/11apriori-guan-lian-fen-xi.html">11.Apriori-关联分析</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第 11 章 使用 Apriori 算法进行关联分析</h1>
<h2>关联分析</h2>
<p>关联分析是一种在大规模数据集中寻找有趣关系的任务。
这些关系可以有两种形式: 
<em> 频繁项集（frequent item sets）: 经常出现在一块的物品的集合。
</em> 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。</p>
<h2>相关术语</h2>
<ul>
<li>
<p>关联分析（关联规则学习): 从大规模数据集中寻找物品间的隐含关系被称作 <code>关联分析(associati analysis)</code> 或者 <code>关联规则学习（association rule learning …</code></p></li></ul></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/11apriori-guan-lian-fen-xi.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/12fp-growth-pin-fan-xiang-ji.html">12.FP-growth-频繁项集</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第12章 使用FP-growth算法来高效发现频繁项集</h1>
<h2>前言</h2>
<p>在 <a href="">第11章</a> 时我们已经介绍了用 <code>Apriori</code> 算法发现 <code>频繁项集</code> 与 <code>关联规则</code>。<br/>
本章将继续关注发现 <code>频繁项集</code> 这一任务，并使用 <code>FP-growth</code> 算法更有效的挖掘 <code>频繁项集</code>。</p>
<h2>FP-growth 算法简介</h2>
<ul>
<li>一种非常好的发现频繁项集算法。</li>
<li>基于Apriori算法构建,但是数据结构不同，使用叫做 <code>FP树</code> 的数据结构结构来存储集合。下面我们会介绍这种数据结构。</li>
</ul>
<h2>FP-growth 算法步骤</h2>
<ul>
<li>基于数据构建FP树 …</li></ul></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/12fp-growth-pin-fan-xiang-ji.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/13li-yong-pcalai-jian-hua-shu-ju.html">13.利用PCA来简化数据</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第13章 利用 PCA 来简化数据</h1>
<h2>降维技术</h2>
<blockquote>
<p>场景</p>
</blockquote>
<ul>
<li>我们正通过电视观看体育比赛，在电视的显示器上有一个球。</li>
<li>显示器大概包含了100万像素点，而球则可能是由较少的像素点组成，例如说一千个像素点。</li>
<li>人们实时的将显示器上的百万像素转换成为一个三维图像，该图像就给出运动场上球的位置。</li>
<li>在这个过程中，人们已经将百万像素点的数据，降至为三维。这个过程就称为<code>降维(dimensionality reduction)</code></li>
</ul>
<blockquote>
<p>数据显示 并非大规模特征下的唯一难题，对数据进行简化还有如下一系列的原因：</p>
</blockquote>
<ul>
<li>1) 使得数据集更容易使用</li>
<li>2) 降低很多算法的计算开销</li>
<li>3) 去除噪音</li>
<li>4 …</li></ul></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/13li-yong-pcalai-jian-hua-shu-ju.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/14li-yong-svdjian-hua-shu-ju.html">14.利用SVD简化数据</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第14章 利用SVD简化数据</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>SVD 概述</h2>
<div class="highlight"><pre><span></span>奇异值分解（SVD, Singular Value Decomposition）:
    提取信息的一种方法，可以把 SVD 看成是从噪声数据中抽取相关特征。从生物信息学到金融学，SVD 是提取信息的强大工具。
</pre></div>
<h2>SVD 场景</h2>
<blockquote>
<p>信息检索-隐性语义检索（Lstent Semantic Indexing, LSI）或 隐形语义分析（Latent Semantic Analysis, LSA）</p>
</blockquote>
<p>隐性语义索引 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/14li-yong-svdjian-hua-shu-ju.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/15da-shu-ju-yu-mapreduce.html">15.大数据与MapReduce</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第15章 大数据与MapReduce</h1>
<h2>大数据 概述</h2>
<p><code>大数据: 收集到的数据已经远远超出了我们的处理能力。</code></p>
<h2>大数据 场景</h2>
<div class="highlight"><pre><span></span>假如你为一家网络购物商店工作，很多用户访问该网站，其中有些人会购买商品，有些人则随意浏览后就离开。
对于你来说，可能很想识别那些有购物意愿的用户。
那么问题就来了，数据集可能会非常大，在单机上训练要运行好几天。
接下来：我们讲讲 MapRedece 如何来解决这样的问题
</pre></div>
<h2>MapRedece</h2>
<h3>Hadoop 概述</h3>
<div class="highlight"><pre><span></span>Hadoop 是 MapRedece 框架的一个免费开源实现。
MapReduce: 分布式的计算框架 …</pre></div></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/15da-shu-ju-yu-mapreduce.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/16tui-jian-xi-tong.html">16.推荐系统</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第16章 推荐系统</h1>
<h2>背景与挖掘目标</h2>
<p>随着互联网的快速发展，用户很难快速从海量信息中寻找到自己感兴趣的信息。因此诞生了：搜索引擎+推荐系统</p>
<p>本章节-推荐系统：</p>
<ol>
<li>帮助用户发现其感兴趣和可能感兴趣的信息。</li>
<li>让网站价值信息脱颖而出，得到广大用户的认可。</li>
<li>提高用户对网站的忠诚度和关注度，建立稳固用户群体。</li>
</ol>
<h2>分析方法与过程</h2>
<p>本案例的目标是对用户进行推荐，即以一定的方式将用户与物品（本次指网页）之间建立联系。</p>
<p>由于用户访问网站的数据记录很多，如果不对数据进行分类处理，对所有的记录直接采用推荐系统进行推荐，这样会存在一下问题。</p>
<ol>
<li>数据量太大意味着物品数与用户数很多，在模型构建用户与物品稀疏矩阵时，出现设备内存空间不够的情况，并且模型计算需要消耗大量的时间。</li>
<li>用户区别很大，不同的用户关注的信息不一样，因此 …</li></ol></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/16tui-jian-xi-tong.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/1ji-qi-xue-xi-ji-chu.html">1.机器学习基础</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第1章 机器学习基础</h1>
<h2>机器学习 概述</h2>
<p><code>机器学习(Machine Learning,ML)</code> 是使用计算机来彰显数据背后的真实含义，它为了把无序的数据转换成有用的信息。是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。
它是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域，它主要使用归纳、综合而不是演绎。</p>
<ol>
<li>海量的数据</li>
<li>获取有用的信息</li>
</ol>
<h2>机器学习 研究意义</h2>
<p>机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/1ji-qi-xue-xi-ji-chu.html">Read On &crarr;</a>
  </footer>
  		</article>
<div class="pagination">
    <a class="prev" href="./index5.html">&larr; Older</a>

    <a class="next" href="./index3.html">Newer &rarr;</a>
  <br />
</div></div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="./pages/2018/01/10fen-zhong-shang-shou-hadoop-hdfschang-yong-wen-jian-ming-ling.html">10分钟上手Hadoop-HDFS常用文件命令</a>
      </li>
      <li class="post">
          <a href="./pages/2018/01/10fen-zhong-shang-shou-latex2.html">10分钟上手Latex2</a>
      </li>
      <li class="post">
          <a href="./pages/2018/01/10fen-zhong-shang-shou-latex3.html">10分钟上手Latex3</a>
      </li>
      <li class="post">
          <a href="./pages/2018/01/10fen-zhong-shang-shou-pandas.html">10分钟上手Pandas</a>
      </li>
      <li class="post">
          <a href="./pages/2018/01/10fen-zhong-shang-shou-pandas3.html">10分钟上手Pandas3</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="./category/00qi-ta.html">00.其他</a></li>
        <li><a href="./category/00qi-ta-2.html">00.其他2</a></li>
        <li><a href="./category/01chang-yong-gong-ju.html">01常用工具</a></li>
        <li><a href="./category/02gong-ju-shi-yong.html">02.工具使用</a></li>
        <li><a href="./category/02wo-ai-du-shu.html">02.我爱读书</a></li>
        <li><a href="./category/03chang-yong-ming-ling.html">03.常用命令</a></li>
        <li><a href="./category/03shen-du-xue-xi.html">03深度学习</a></li>
        <li><a href="./category/book-pydata.html">book-pydata</a></li>
        <li><a href="./category/ji-chu-zhi-shi.html">基础知识</a></li>
        <li><a href="./category/ji-qi-xue-xi-shi-zhan.html">机器学习实战</a></li>
        <li><a href="./category/shen-du-xue-xi.html">深度学习</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="./tag/gong-ju.html">工具</a>,    <a href="./tag/tensorflowexample.html">TensorFlowExample</a>,    <a href="./tag/tensorflow.html">tensorflow</a>,    <a href="./tag/shen-du-xue-xi.html">深度学习</a>,    <a href="./tag/jupyter.html">jupyter</a>,    <a href="./tag/python.html">python</a>,    <a href="./tag/book.html">book</a>,    <a href="./tag/pydata.html">pydata</a>,    <a href="./tag/pyhton.html">pyhton</a>,    <a href="./tag/xgboost.html">xgboost</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="#" target="_blank">You can add links in your config file</a></li>
            <li><a href="#" target="_blank">Another social link</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://getpelican.com/" target="_blank">Pelican</a></li>
            <li><a href="http://python.org/" target="_blank">Python.org</a></li>
            <li><a href="http://jinja.pocoo.org/" target="_blank">Jinja2</a></li>
            <li><a href="#" target="_blank">You can modify those links in your config file</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2017&ndash;2018  niult &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="./theme/js/modernizr-2.0.js"></script>
  <script src="./theme/js/ender.js"></script>
  <script src="./theme/js/octopress.js" type="text/javascript"></script>
</body>
</html>