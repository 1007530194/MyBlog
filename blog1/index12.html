<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!-->
<html class="no-js" lang="en"><!--<![endif]-->
    <head>
<meta charset="utf-8">
<title>魑魅魍魉</title>
<meta name="author" content="niult">




<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="./favicon.png" rel="icon">

<link href="./theme/css/main.css" media="screen, projection"
      rel="stylesheet" type="text/css">

<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
      rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
      rel="stylesheet" type="text/css">
</head>

<body>
<header role="banner"><hgroup>
  <h1><a href="./">魑魅魍魉</a></h1>
</hgroup></header>
<nav role="navigation">    <ul class="subscription" data-subscription="rss">
    </ul>


<ul class="main-navigation">
            <li >
                <a href="./category/01chang yong gong ju.html">01常用工具</a>
            </li>
            <li >
                <a href="./category/02.wo ai du shu.html">02.我爱读书</a>
            </li>
            <li >
                <a href="./category/algorithms.html">Algorithms</a>
            </li>
            <li >
                <a href="./category/book.html">Book</a>
            </li>
            <li >
                <a href="./category/book-pydata.html">Book-pydata</a>
            </li>
            <li >
                <a href="./category/deep-learning-with-python.html">Deep-learning-with-python</a>
            </li>
            <li >
                <a href="./category/ji qi xue xi shi zhan.html">机器学习实战</a>
            </li>
            <li >
                <a href="./category/ling ji chu ru men shen du xue xi.html">零基础入门深度学习</a>
            </li>
            <li >
                <a href="./category/shen du xue xi.html">深度学习</a>
            </li>
            <li >
                <a href="./category/shu xue ji chu.html">数学基础</a>
            </li>
            <li >
                <a href="./category/tf-example.html">Tf-example</a>
            </li>
            <li >
                <a href="./category/tool1.html">Tool1</a>
            </li>
            <li >
                <a href="./category/tool2.html">Tool2</a>
            </li>
            <li >
                <a href="./category/tools.html">Tools</a>
            </li>
            <li >
                <a href="./category/tui jian xi tong.html">推荐系统</a>
            </li>
            <li >
                <a href="./category/wen ben wa jue.html">文本挖掘</a>
            </li>
</ul>
</nav>
<div id="main">
    <div id="content">
    <div class="blog-index">
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/15da-shu-ju-yu-mapreduce.html">15.大数据与MapReduce</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第15章 大数据与MapReduce</h1>
<h2>大数据 概述</h2>
<p><code>大数据: 收集到的数据已经远远超出了我们的处理能力。</code></p>
<h2>大数据 场景</h2>
<div class="highlight"><pre><span></span>假如你为一家网络购物商店工作，很多用户访问该网站，其中有些人会购买商品，有些人则随意浏览后就离开。
对于你来说，可能很想识别那些有购物意愿的用户。
那么问题就来了，数据集可能会非常大，在单机上训练要运行好几天。
接下来：我们讲讲 MapRedece 如何来解决这样的问题
</pre></div>
<h2>MapRedece</h2>
<h3>Hadoop 概述</h3>
<div class="highlight"><pre><span></span>Hadoop 是 MapRedece 框架的一个免费开源实现。
MapReduce: 分布式的计算框架 …</pre></div></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/15da-shu-ju-yu-mapreduce.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/16tui-jian-xi-tong.html">16.推荐系统</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第16章 推荐系统</h1>
<h2>背景与挖掘目标</h2>
<p>随着互联网的快速发展，用户很难快速从海量信息中寻找到自己感兴趣的信息。因此诞生了：搜索引擎+推荐系统</p>
<p>本章节-推荐系统：</p>
<ol>
<li>帮助用户发现其感兴趣和可能感兴趣的信息。</li>
<li>让网站价值信息脱颖而出，得到广大用户的认可。</li>
<li>提高用户对网站的忠诚度和关注度，建立稳固用户群体。</li>
</ol>
<h2>分析方法与过程</h2>
<p>本案例的目标是对用户进行推荐，即以一定的方式将用户与物品（本次指网页）之间建立联系。</p>
<p>由于用户访问网站的数据记录很多，如果不对数据进行分类处理，对所有的记录直接采用推荐系统进行推荐，这样会存在一下问题。</p>
<ol>
<li>数据量太大意味着物品数与用户数很多，在模型构建用户与物品稀疏矩阵时，出现设备内存空间不够的情况，并且模型计算需要消耗大量的时间。</li>
<li>用户区别很大，不同的用户关注的信息不一样，因此 …</li></ol></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/16tui-jian-xi-tong.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/1ji-qi-xue-xi-ji-chu.html">1.机器学习基础</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第1章 机器学习基础</h1>
<h2>机器学习 概述</h2>
<p><code>机器学习(Machine Learning,ML)</code> 是使用计算机来彰显数据背后的真实含义，它为了把无序的数据转换成有用的信息。是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。
它是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域，它主要使用归纳、综合而不是演绎。</p>
<ol>
<li>海量的数据</li>
<li>获取有用的信息</li>
</ol>
<h2>机器学习 研究意义</h2>
<p>机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能 …</p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/1ji-qi-xue-xi-ji-chu.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/2k-jin-lin-suan-fa.html">2.k-近邻算法</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第2章 k-近邻算法</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>KNN 概述</h2>
<p><code>k-近邻（kNN, k-NearestNeighbor）算法是一种基本分类与回归方法，我们这里只讨论分类问题中的 k-近邻算法。</code></p>
<p><strong>一句话总结：近朱者赤近墨者黑！</strong> </p>
<p><code>k 近邻算法的输入为实例的特征向量，对应于特征空间的点；输出为实例的类别，可以取多类。k 近邻算法假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其 k 个最近邻的训练实例的类别，通过多数表决等方式进行预测。因此，k近邻算法不具有显式的学习过程。</code></p>
<p><code>k 近邻算法实际上利用训练数据集对特征向量空间进行划分 …</code></p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/2k-jin-lin-suan-fa.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/3jue-ce-shu.html">3.决策树</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第3章 决策树</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>决策树 概述</h2>
<p><code>决策树（Decision Tree）算法是一种基本的分类与回归方法，是最经常使用的数据挖掘算法之一。我们这章节只讨论用于分类的决策树。</code></p>
<p><code>决策树模型呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。它可以认为是 if-then 规则的集合，也可以认为是定义在特征空间与类空间上的条件概率分布。</code></p>
<p><code>决策树学习通常包括 3 个步骤：特征选择、决策树的生成和决策树的修剪。</code></p>
<h2>决策树 场景</h2>
<p>一个叫做 "二十个问题" 的游戏，游戏的规则很简单：参与游戏的一方在脑海中想某个事物，其他参与者向他提问 …</p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/3jue-ce-shu.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/4po-su-bei-xie-si.html">4.朴素贝叶斯</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第4章 基于概率论的分类方法：朴素贝叶斯</h1>
<h2>朴素贝叶斯 概述</h2>
<p><code>贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。本章首先介绍贝叶斯分类算法的基础——贝叶斯定理。最后，我们通过实例来讨论贝叶斯分类的中最简单的一种: 朴素贝叶斯分类。</code></p>
<h2>贝叶斯理论 &amp; 条件概率</h2>
<h3>贝叶斯理论</h3>
<p>我们现在有一个数据集，它由两类数据组成，数据分布如下图所示：</p>
<p><img alt="朴素贝叶斯示例数据分布" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/4.NaiveBayesian/朴素贝叶斯示例数据分布.png" title="参数已知的概率分布"/></p>
<p>我们现在用 p1(x,y) 表示数据点 (x,y) 属于类别 1（图中用圆点表示的类别）的概率 …</p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/4po-su-bei-xie-si.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/5logistichui-gui.html">5.Logistic回归</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第5章 Logistic回归</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>Logistic 回归 概述</h2>
<p><code>Logistic 回归 或者叫逻辑回归 虽然名字有回归，但是它是用来做分类的。其主要思想是: 根据现有数据对分类边界线(Decision Boundary)建立回归公式，以此进行分类。</code></p>
<h2>须知概念</h2>
<h3>Sigmoid 函数</h3>
<h4>回归 概念</h4>
<p>假设现在有一些数据点，我们用一条直线对这些点进行拟合（这条直线称为最佳拟合直线），这个拟合的过程就叫做回归。进而可以得到对这些点的拟合直线方程，那么我们根据这个回归方程，怎么进行分类呢？请看下面。</p>
<h4>二值型输出分类函数 …</h4></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/5logistichui-gui.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/61zhi-chi-xiang-liang-ji-de-li-jie.html">6.1.支持向量机的理解</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>SVM</h1>
<blockquote>
<p>声明</p>
</blockquote>
<div class="highlight"><pre><span></span>阅读本文前，需要您懂一些高等数学、概率论、线性代数的相关知识，以便更好理解。
</pre></div>
<div class="highlight"><pre><span></span>下面这些关于 SVM 的理解，是根据知乎和其他博客或者网站中查询到的资料加以整理，
并结合 ApacheCN 这段时间的撸代码和相关研究得到，有理解有误的地方还望大家指出，谢谢。
再次感谢网上的大佬们的无私贡献。

ApacheCN: http://www.apachecn.org/
ApacheCN MachineLearning github: https://github.com/apachecn/MachineLearning …</pre></div></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/61zhi-chi-xiang-liang-ji-de-li-jie.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/6zhi-chi-xiang-liang-ji.html">6.支持向量机</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第6章 支持向量机</h1>
<h2>支持向量机 概述</h2>
<p>支持向量机(Support Vector Machines, SVM)：是一种机器学习算法。
<em> 支持向量(Support Vector)就是离分隔超平面最近的那些点。
</em> 机(Machine)就是表示一种算法，而不是表示机器。</p>
<h2>支持向量机 场景</h2>
<ul>
<li>要给左右两边的点进行分类</li>
<li>明显发现：选择D会比B、C分隔的效果要好很多。</li>
</ul>
<p><img alt="线性可分" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/6.SVM/SVM_3_linearly-separable.jpg?raw=true"/></p>
<h2>支持向量机 原理</h2>
<h3>SVM 工作原理</h3>
<p><img alt="k_2" src="https://github.com/1007530194/datas/blob/master/images/blog/books/deeplearningdo/6.SVM/k_2.jpg" title="k_2"/></p>
<p>对于上述的苹果和香蕉，我们想象为2种水果类型的炸弹 …</p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/6zhi-chi-xiang-liang-ji.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/7ji-cheng-fang-fa-sui-ji-sen-lin-he-adaboost.html">7.集成方法-随机森林和AdaBoost</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第7章 集成方法 ensemble method</h1>
<h2>集成方法: ensemble method（元算法: meta algorithm） 概述</h2>
<ul>
<li>概念：是对其他算法进行组合的一种形式。</li>
<li>
<p>通俗来说： 当做重要决定时，大家可能都会考虑吸取多个专家而不只是一个人的意见。
    机器学习处理问题时又何尝不是如此？ 这就是集成方法背后的思想。</p>
</li>
<li>
<p>集成方法：  </p>
<ol>
<li>投票选举(bagging: 自举汇聚法 bootstrap aggregating): 是基于数据随机重抽样分类器构造的方法</li>
<li>再学习(boosting): 是基于所有分类器的加权求和的方法</li>
</ol>
</li>
</ul>
<h2>集成方法 场景 …</h2></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/7ji-cheng-fang-fa-sui-ji-sen-lin-he-adaboost.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/8yu-ce-shu-zhi-xing-shu-ju-hui-gui.html">8.预测数值型数据：回归</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第8章 预测数值型数据：回归</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>回归（Regression） 概述</h2>
<p><code>我们前边提到的分类的目标变量是标称型数据，而回归则是对连续型的数据做出处理，回归的目的是预测数值型数据的目标值。</code></p>
<h2>回归 场景</h2>
<p>回归的目的是预测数值型的目标值。最直接的办法是依据输入写出一个目标值的计算公式。</p>
<p>假如你想要预测兰博基尼跑车的功率大小，可能会这样计算:</p>
<p>HorsePower = 0.0015 * annualSalary - 0.99 * hoursListeningToPublicRadio</p>
<p>这就是所谓的 <code>回归方程(regression equation)</code>，其中的 0.0015 和 …</p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/8yu-ce-shu-zhi-xing-shu-ju-hui-gui.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/9shu-hui-gui.html">9.树回归</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h1>第9章 树回归</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>树回归 概述</h2>
<p><code>我们本章介绍 CART(Classification And Regression Trees， 分类回归树) 的树构建算法。该算法既可以用于分类还可以用于回归。</code></p>
<h2>树回归 场景</h2>
<p>我们在第 8 章中介绍了线性回归的一些强大的方法，但这些方法创建的模型需要拟合所有的样本点（局部加权线性回归除外）。当数据拥有众多特征并且特征之间关系十分复杂时，构建全局模型的想法就显得太难了，也略显笨拙。而且，实际生活中很多问题都是非线性的，不可能使用全局线性模型来拟合任何数据。</p>
<p>一种可行的方法是将数据集切分成很多份易建模的数据，然后利用我们的线性回归技术来建模。如果首次切分后仍然难以拟合线性模型就继续切分。在这种切分方式下 …</p></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/9shu-hui-gui.html">Read On &crarr;</a>
        </footer>


                </article>
                <article>
<header>
        <h1 class="entry-title">
            <a href="./pages/2017/01/naive-bayes-discuss.html">naive-bayes-discuss</a>
        </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

    <div class="entry-content"><h2>朴素贝叶斯讨论</h2>
<blockquote>
<p><a href="https://github.com/Timehsw">@Time渐行渐远</a> <a href="https://github.com/wangyangting">@那伊抹微笑</a> <a href="https://github.com/chenyyx">@小瑶</a> <a href="https://github.com/orgs/apachecn/people/mikechengwei">@如果迎着风就飞</a></p>
</blockquote>
<p>朴素贝叶斯就是用来求逆向概率的（已知）。</p>
<ol>
<li>根据训练数据集求（正向）概率。</li>
<li>根据测试数据集求（逆向）概率（根据 贝叶斯公式）。</li>
<li>求出的逆向概率，哪个大，就属于哪个类别。</li>
</ol>
<h3>疑问 1</h3>
<p>通过训练集求出了各个特征的概率, 然后测试集的特征和之前求出来的概率相乘, 这个就代表这个测试集的特征的概率了.
有了这个基础后, 通过贝叶斯公式, 就可以得到这个测试集的特征属于哪个类别了, 他们相乘的依据是什么？</p>
<div class="highlight"><pre><span></span>朴素贝叶斯？
条件独立性啊
朴素贝叶斯不是基于两个定理吗 …</pre></div></div>
        <footer>
            <a rel="full-article" href="./pages/2017/01/naive-bayes-discuss.html">Read On &crarr;</a>
        </footer>


                </article>
<div class="pagination">

    <a class="next" href="./index11.html">Newer &rarr;</a>
  <br />
</div>    </div>
<aside class="sidebar">
    <section>
        <h1>Recent Posts</h1>
        <ul id="recent_posts">
                <li class="post">
                    <a href="./pages/2019/01/21-a-first-look-at-a-neural-network.html">2.1-a-first-look-at-a-neural-network</a>
                </li>
                <li class="post">
                    <a href="./pages/2019/01/35-classifying-movie-reviews.html">3.5-classifying-movie-reviews</a>
                </li>
                <li class="post">
                    <a href="./pages/2019/01/36-classifying-newswires.html">3.6-classifying-newswires</a>
                </li>
                <li class="post">
                    <a href="./pages/2019/01/37-predicting-house-prices.html">3.7-predicting-house-prices</a>
                </li>
                <li class="post">
                    <a href="./pages/2019/01/44-overfitting-and-underfitting.html">4.4-overfitting-and-underfitting</a>
                </li>
        </ul>
    </section>
        <section>

            <h1>Categories</h1>
            <ul id="recent_posts">
                    <li><a href="./category/01chang yong gong ju.html">01常用工具</a></li>
                    <li><a href="./category/02.wo ai du shu.html">02.我爱读书</a></li>
                    <li><a href="./category/algorithms.html">algorithms</a></li>
                    <li><a href="./category/book.html">book</a></li>
                    <li><a href="./category/book-pydata.html">book-pydata</a></li>
                    <li><a href="./category/deep-learning-with-python.html">deep-learning-with-python</a></li>
                    <li><a href="./category/ji qi xue xi shi zhan.html">机器学习实战</a></li>
                    <li><a href="./category/ling ji chu ru men shen du xue xi.html">零基础入门深度学习</a></li>
                    <li><a href="./category/shen du xue xi.html">深度学习</a></li>
                    <li><a href="./category/shu xue ji chu.html">数学基础</a></li>
                    <li><a href="./category/tf-example.html">tf-example</a></li>
                    <li><a href="./category/tool1.html">tool1</a></li>
                    <li><a href="./category/tool2.html">tool2</a></li>
                    <li><a href="./category/tools.html">tools</a></li>
                    <li><a href="./category/tui jian xi tong.html">推荐系统</a></li>
                    <li><a href="./category/wen ben wa jue.html">文本挖掘</a></li>
            </ul>
        </section>


    <section>
        <h1>Tags</h1>
            <a href="./tag/python.html">python</a>, 
            <a href="./tag/numpy.html">numpy</a>, 
            <a href="./tag/deep-learning.html">deep-learning</a>, 
            <a href="./tag/algorithms.html">algorithms</a>, 
            <a href="./tag/wen-ben-wa-jue.html">文本挖掘</a>, 
            <a href="./tag/shu-xue-ji-chu.html">数学基础</a>, 
            <a href="./tag/nlp.html">nlp</a>, 
            <a href="./tag/tf-example.html">tf-example</a>, 
            <a href="./tag/tui-jian-xi-tong.html">推荐系统</a>, 
            <a href="./tag/tf.html">tf</a>, 
            <a href="./tag/ji-huo-han-shu.html">激活函数</a>, 
            <a href="./tag/sun-shi-han-shu.html">损失函数</a>, 
            <a href="./tag/mapreduce.html">mapreduce</a>, 
            <a href="./tag/spark.html">spark</a>, 
            <a href="./tag/handbook.html">handbook</a>, 
            <a href="./tag/matplotlib.html">matplotlib</a>, 
            <a href="./tag/scikit-learn.html">scikit-learn</a>, 
            <a href="./tag/latex.html">latex</a>, 
            <a href="./tag/pandas.html">pandas</a>, 
            <a href="./tag/jupyter.html">jupyter</a>, 
            <a href="./tag/plot.html">plot</a>, 
            <a href="./tag/pip.html">pip</a>, 
            <a href="./tag/geng-xin-suo-you-mo-kuai.html">更新所有模块</a>, 
            <a href="./tag/shen-du-xue-xi.html">深度学习</a>, 
            <a href="./tag/xun-huan-shen-jing-wang-luo.html">循环神经网络</a>, 
            <a href="./tag/pangrank.html">PangRank</a>, 
            <a href="./tag/book.html">book</a>, 
            <a href="./tag/pydata.html">pydata</a>, 
            <a href="./tag/shell.html">shell</a>, 
            <a href="./tag/pyhton.html">pyhton</a>
    </section>



    <section>
        <h1>GitHub Repos</h1>
        <ul id="gh_repos">
            <li class="loading">Status updating...</li>
        </ul>
            <a href="https://github.com/1007530194">@1007530194</a> on GitHub
        <script type="text/javascript">
            $.domReady(function () {
                if (!window.jXHR) {
                    var jxhr = document.createElement('script');
                    jxhr.type = 'text/javascript';
                    jxhr.src = './theme/js/jXHR.js';
                    var s = document.getElementsByTagName('script')[0];
                    s.parentNode.insertBefore(jxhr, s);
                }

                github.showRepos({
                    user: '1007530194',
                    count: 5,
                    skip_forks: false,
                    target: '#gh_repos'
                });
            });
        </script>
        <script src="./theme/js/github.js" type="text/javascript"></script>
    </section>

</aside>    </div>
</div>
<footer role="contentinfo"><p>
        活到老，学到老，玩到老
    <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
<script src="./theme/js/modernizr-2.0.js"></script>
<script src="./theme/js/ender.js"></script>
<script src="./theme/js/octopress.js" type="text/javascript"></script>
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-132396898-1', 'auto');

    ga('require', 'displayfeatures');
    ga('send', 'pageview');
    </script>
</body>
</html>