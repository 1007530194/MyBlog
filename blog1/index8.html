<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>魑魅魍魉</title>
  <meta name="author" content="niult">




  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="./favicon.png" rel="icon">

  <link href="./theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="./">魑魅魍魉</a></h1>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>


<ul class="main-navigation">
      <li >
        <a href="./category/01chang-yong-gong-ju.html">01常用工具</a>
      </li>
      <li >
        <a href="./category/02wo-ai-du-shu.html">02.我爱读书</a>
      </li>
      <li >
        <a href="./category/book-pydata.html">Book-pydata</a>
      </li>
      <li >
        <a href="./category/ji-chu-zhi-shi.html">基础知识</a>
      </li>
      <li >
        <a href="./category/ji-qi-xue-xi-shi-zhan.html">机器学习实战</a>
      </li>
      <li >
        <a href="./category/ling-ji-chu-ru-men-shen-du-xue-xi.html">零基础入门深度学习</a>
      </li>
      <li >
        <a href="./category/shen-du-xue-xi.html">深度学习</a>
      </li>
      <li >
        <a href="./category/tf-example.html">Tf-example</a>
      </li>
      <li >
        <a href="./category/tools.html">Tools</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div class="blog-index">
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/tong-ji-xue-xi-fang-fa-07-zhi-chi-xiang-liang-ji.html">统计学习方法07-支持向量机</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="第7章-支持向量机">&#31532;7&#31456; &#25903;&#25345;&#21521;&#37327;&#26426;<a class="anchor-link" href="#第7章-支持向量机">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<p>分离超平面：$w^Tx+b=0$</p>
<p>点到直线距离：$r=\frac{|w^Tx+b|}{||w||_2}$</p>
<p>$||w||_2$为2-范数：$||w||_2=\sqrt[2]{\sum^m_{i=1}w_i^2}$</p>
<p>直线为超平面，样本可表示为：</p>
<p>$w^Tx+b\ \geq+1$</p>
<p>$w^Tx+b\ \leq+1$</p>
<h4 id="margin：">margin&#65306;<a class="anchor-link" href="#margin：">&#182;</a></h4><p><strong>函数间隔</strong>：$label(w^Tx+b)\ or\ y_i(w^Tx+b)$</p>
<p><strong>几何间隔</strong>：$r=\frac{label(w^Tx+b)}{||w||_2}$，当数据被正确分类时，几何间隔就是点到超平面的距离</p>
<p>为了求几何间隔最大，SVM基本问题可以转化为求解:($\frac{r^*}{||w||}$为几何间隔，(${r^*}$为函数间隔)</p>
<p>$$\max\ \frac{r^*}{||w||}$$</p>
<p>$$(subject\ to)\ y_i({w^T}x_i+{b})\geq {r^*},\ i=1,2,..,m$$</p>
<p>分类点几何间隔最大，同时被正确分类。但这个方程并非凸函数求解，所以要先①将方程转化为凸函数，②用拉格朗日乘子法和KKT条件求解对偶问题。</p>
<p>①转化为凸函数：</p>
<p>先令${r^*}=1$，方便计算（参照衡量，不影响评价结果）</p>
<p>$$\max\ \frac{1}{||w||}$$</p>
<p>$$s.t.\ y_i({w^T}x_i+{b})\geq {1},\ i=1,2,..,m$$</p>
<p>再将$\max\ \frac{1}{||w||}$转化成$\min\ \frac{1}{2}||w||^2$求解凸函数，1/2是为了求导之后方便计算。</p>
<p>$$\min\ \frac{1}{2}||w||^2$$</p>
<p>$$s.t.\ y_i(w^Tx_i+b)\geq 1,\ i=1,2,..,m$$</p>
<p>②用拉格朗日乘子法和KKT条件求解最优值：</p>
<p>$$\min\ \frac{1}{2}||w||^2$$</p>
<p>$$s.t.\ -y_i(w^Tx_i+b)+1\leq 0,\ i=1,2,..,m$$</p>
<p>整合成：</p>
<p>$$L(w, b, \alpha) = \frac{1}{2}||w||^2+\sum^m_{i=1}\alpha_i(-y_i(w^Tx_i+b)+1)$$</p>
<p>推导：$\min\ f(x)=\min \max\ L(w, b, \alpha)\geq \max \min\ L(w, b, \alpha)$</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/tong-ji-xue-xi-fang-fa-07-zhi-chi-xiang-liang-ji.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/tong-ji-xue-xi-fang-fa-08-ti-sheng-fang-fa.html">统计学习方法08-提升方法</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="第8章-提升方法">&#31532;8&#31456; &#25552;&#21319;&#26041;&#27861;<a class="anchor-link" href="#第8章-提升方法">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Boost">Boost<a class="anchor-link" href="#Boost">&#182;</a></h1><p>“装袋”（bagging）和“提升”（boost）是构建组合模型的两种最主要的方法，所谓的组合模型是由多个基本模型构成的模型，组合模型的预测效果往往比任意一个基本模型的效果都要好。</p>
<ul>
<li><p>装袋：每个基本模型由从总体样本中随机抽样得到的不同数据集进行训练得到，通过重抽样得到不同训练数据集的过程称为装袋。</p>
</li>
<li><p>提升：每个基本模型训练时的数据集采用不同权重，针对上一个基本模型分类错误的样本增加权重，使得新的模型重点关注误分类样本</p>
</li>
</ul>
<h3 id="AdaBoost">AdaBoost<a class="anchor-link" href="#AdaBoost">&#182;</a></h3><p>AdaBoost是AdaptiveBoost的缩写，表明该算法是具有适应性的提升算法。</p>
<p>算法的步骤如下：</p>
<p>1）给每个训练样本（$x_{1},x_{2},….,x_{N}$）分配权重，初始权重$w_{1}$均为1/N。</p>
<p>2）针对带有权值的样本进行训练，得到模型$G_m$（初始模型为G1）。</p>
<p>3）计算模型$G_m$的误分率$e_m=\sum_{i=1}^Nw_iI(y_i\not= G_m(x_i))$</p>
<p>4）计算模型$G_m$的系数$\alpha_m=0.5\log[(1-e_m)/e_m]$</p>
<p>5）根据误分率e和当前权重向量$w_m$更新权重向量$w_{m+1}$。</p>
<p>6）计算组合模型$f(x)=\sum_{m=1}^M\alpha_mG_m(x_i)$的误分率。</p>
<p>7）当组合模型的误分率或迭代次数低于一定阈值，停止迭代；否则，回到步骤2）</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/tong-ji-xue-xi-fang-fa-08-ti-sheng-fang-fa.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/tong-ji-xue-xi-fang-fa-09-suan-fa-ji-qi-tui-yan.html">统计学习方法09-算法及其推广</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="第9章-EM算法及其推广">&#31532;9&#31456; EM&#31639;&#27861;&#21450;&#20854;&#25512;&#24191;<a class="anchor-link" href="#第9章-EM算法及其推广">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Expectation-Maximization-algorithm">Expectation Maximization algorithm<a class="anchor-link" href="#Expectation-Maximization-algorithm">&#182;</a></h1><h3 id="Maximum-likehood-function">Maximum likehood function<a class="anchor-link" href="#Maximum-likehood-function">&#182;</a></h3><p><a href="http://fangs.in/post/thinkstats/likelihood/">likehood &amp; maximum likehood</a></p>
<blockquote><p>在统计学中，似然函数（likelihood function，通常简写为likelihood，似然）是一个非常重要的内容，在非正式场合似然和概率（Probability）几乎是一对同义词，但是在统计学中似然和概率却是两个不同的概念。概率是在特定环境下某件事情发生的可能性，也就是结果没有产生之前依据环境所对应的参数来预测某件事情发生的可能性，比如抛硬币，抛之前我们不知道最后是哪一面朝上，但是根据硬币的性质我们可以推测任何一面朝上的可能性均为50%，这个概率只有在抛硬币之前才是有意义的，抛完硬币后的结果便是确定的；而似然刚好相反，是在确定的结果下去推测产生这个结果的可能环境（参数），还是抛硬币的例子，假设我们随机抛掷一枚硬币1,000次，结果500次人头朝上，500次数字朝上（实际情况一般不会这么理想，这里只是举个例子），我们很容易判断这是一枚标准的硬币，两面朝上的概率均为50%，这个过程就是我们运用出现的结果来判断这个事情本身的性质（参数），也就是似然。</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>$$P(Y|\theta) = \prod[\pi p^{y_i}(1-p)^{1-y_i}+(1-\pi) q^{y_i}(1-q)^{1-y_i}]$$</p>
<h3 id="E-step:">E step:<a class="anchor-link" href="#E-step:">&#182;</a></h3><p>$$\mu^{i+1}=\frac{\pi (p^i)^{y_i}(1-(p^i))^{1-y_i}}{\pi (p^i)^{y_i}(1-(p^i))^{1-y_i}+(1-\pi) (q^i)^{y_i}(1-(q^i))^{1-y_i}}$$</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/tong-ji-xue-xi-fang-fa-09-suan-fa-ji-qi-tui-yan.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/tong-ji-xue-xi-fang-fa-10-yin-ma-er-ke-fu-mo-xing.html">统计学习方法10-隐马尔科夫模型</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="第10章-隐马尔可夫模型">&#31532;10&#31456; &#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;<a class="anchor-link" href="#第10章-隐马尔可夫模型">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/tong-ji-xue-xi-fang-fa-10-yin-ma-er-ke-fu-mo-xing.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/tong-ji-xue-xi-fang-fa-11-tiao-jian-sui-ji-chang.html">统计学习方法11-条件随机场</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content">
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="第11章-条件随机场">&#31532;11&#31456; &#26465;&#20214;&#38543;&#26426;&#22330;<a class="anchor-link" href="#第11章-条件随机场">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="例11.1">&#20363;11.1<a class="anchor-link" href="#例11.1">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input"></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/tong-ji-xue-xi-fang-fa-11-tiao-jian-sui-ji-chang.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/zhu-cheng-fen-fen-xi.html">主成分分析</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><p>转载请声明出处：<a href="http://blog.csdn.net/zhongkelee/article/details/44064401">http://blog.csdn.net/zhongkelee/article/details/44064401</a></p>
<h1><strong>一、PCA简介</strong></h1>
<h2><strong>1. 相关背景</strong></h2>
<p>上完陈恩红老师的《机器学习与知识发现》和季海波老师的《矩阵代数》两门课之后，颇有体会。最近在做主成分分析和奇异值分解方面的项目，所以记录一下心得体会。</p>
<p>在许多领域的研究与应用中，往往需要对反映事物的多个变量进行大量的观测，收集大量数据以便进行分析寻找规律。多变量大样本无疑会为研究和应用提供了丰富的信息，但也在一定程度上增加了数据采集的工作量，更重要的是在多数情况下，许多变量之间可能存在相关性，从而增加了问题分析的复杂性，同时对分析带来不便 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/zhu-cheng-fen-fen-xi.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2018/01/zui-xiao-er-cheng-fa.html">最小二乘法</a>
      </h1>
    <p class="meta">
<time datetime="2018-01-01T00:00:00+08:00" pubdate>2018-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>最小二乘法</h1>
<p>我们从矩阵的角度来理解： 
首先我们给出一个矩阵中的定义： </p>
<p>$$R(A)={Ax|x∈R^n},A∈R^{n×n}$$</p>
<p>有了上面的定义之后，我们就可以写出最小二乘问题的矩阵形式： </p>
<p>$$∃b∉R(A),b∈R^n,\min_{x∈R^n}\parallel Ax−b\parallel _2 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2018/01/zui-xiao-er-cheng-fa.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/10k-meansju-lei.html">10.k-means聚类</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第 10 章 K-Means（K-均值）聚类算法</h1>
<h2>K-Means 算法</h2>
<p>聚类是一种无监督的学习, 它将相似的对象归到一个簇中, 将不相似对象归到不同簇中.<br/>
相似这一概念取决于所选择的相似度计算方法.<br/>
K-Means 是发现给定数据集的 K 个簇的聚类算法, 之所以称之为 <code>K-均值</code> 是因为它可以发现 K 个不同的簇, 且每个簇的中心采用簇中所含值的均值计算而成.<br/>
簇个数 K 是用户指定的, 每一个簇通过其质心（centroid）, 即簇中所有点的中心来描述.<br/>
聚类与分类算法的最大区别在于, 分类的目标类别已知 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/10k-meansju-lei.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/11apriori-guan-lian-fen-xi.html">11.Apriori-关联分析</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第 11 章 使用 Apriori 算法进行关联分析</h1>
<h2>关联分析</h2>
<p>关联分析是一种在大规模数据集中寻找有趣关系的任务。
这些关系可以有两种形式: 
<em> 频繁项集（frequent item sets）: 经常出现在一块的物品的集合。
</em> 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。</p>
<h2>相关术语</h2>
<ul>
<li>
<p>关联分析（关联规则学习): 从大规模数据集中寻找物品间的隐含关系被称作 <code>关联分析(associati analysis)</code> 或者 <code>关联规则学习（association rule learning …</code></p></li></ul></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/11apriori-guan-lian-fen-xi.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/12fp-growth-pin-fan-xiang-ji.html">12.FP-growth-频繁项集</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第12章 使用FP-growth算法来高效发现频繁项集</h1>
<h2>前言</h2>
<p>在 <a href="">第11章</a> 时我们已经介绍了用 <code>Apriori</code> 算法发现 <code>频繁项集</code> 与 <code>关联规则</code>。<br/>
本章将继续关注发现 <code>频繁项集</code> 这一任务，并使用 <code>FP-growth</code> 算法更有效的挖掘 <code>频繁项集</code>。</p>
<h2>FP-growth 算法简介</h2>
<ul>
<li>一种非常好的发现频繁项集算法。</li>
<li>基于Apriori算法构建,但是数据结构不同，使用叫做 <code>FP树</code> 的数据结构结构来存储集合。下面我们会介绍这种数据结构。</li>
</ul>
<h2>FP-growth 算法步骤</h2>
<ul>
<li>基于数据构建FP树 …</li></ul></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/12fp-growth-pin-fan-xiang-ji.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/13li-yong-pcalai-jian-hua-shu-ju.html">13.利用PCA来简化数据</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第13章 利用 PCA 来简化数据</h1>
<h2>降维技术</h2>
<blockquote>
<p>场景</p>
</blockquote>
<ul>
<li>我们正通过电视观看体育比赛，在电视的显示器上有一个球。</li>
<li>显示器大概包含了100万像素点，而球则可能是由较少的像素点组成，例如说一千个像素点。</li>
<li>人们实时的将显示器上的百万像素转换成为一个三维图像，该图像就给出运动场上球的位置。</li>
<li>在这个过程中，人们已经将百万像素点的数据，降至为三维。这个过程就称为<code>降维(dimensionality reduction)</code></li>
</ul>
<blockquote>
<p>数据显示 并非大规模特征下的唯一难题，对数据进行简化还有如下一系列的原因：</p>
</blockquote>
<ul>
<li>1) 使得数据集更容易使用</li>
<li>2) 降低很多算法的计算开销</li>
<li>3) 去除噪音</li>
<li>4 …</li></ul></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/13li-yong-pcalai-jian-hua-shu-ju.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/14li-yong-svdjian-hua-shu-ju.html">14.利用SVD简化数据</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第14章 利用SVD简化数据</h1>
<p><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default" type="text/javascript"></script></p>
<h2>SVD 概述</h2>
<div class="highlight"><pre><span></span>奇异值分解（SVD, Singular Value Decomposition）:
    提取信息的一种方法，可以把 SVD 看成是从噪声数据中抽取相关特征。从生物信息学到金融学，SVD 是提取信息的强大工具。
</pre></div>
<h2>SVD 场景</h2>
<blockquote>
<p>信息检索-隐性语义检索（Lstent Semantic Indexing, LSI）或 隐形语义分析（Latent Semantic Analysis, LSA）</p>
</blockquote>
<p>隐性语义索引 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/14li-yong-svdjian-hua-shu-ju.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/15da-shu-ju-yu-mapreduce.html">15.大数据与MapReduce</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第15章 大数据与MapReduce</h1>
<h2>大数据 概述</h2>
<p><code>大数据: 收集到的数据已经远远超出了我们的处理能力。</code></p>
<h2>大数据 场景</h2>
<div class="highlight"><pre><span></span>假如你为一家网络购物商店工作，很多用户访问该网站，其中有些人会购买商品，有些人则随意浏览后就离开。
对于你来说，可能很想识别那些有购物意愿的用户。
那么问题就来了，数据集可能会非常大，在单机上训练要运行好几天。
接下来：我们讲讲 MapRedece 如何来解决这样的问题
</pre></div>
<h2>MapRedece</h2>
<h3>Hadoop 概述</h3>
<div class="highlight"><pre><span></span>Hadoop 是 MapRedece 框架的一个免费开源实现。
MapReduce: 分布式的计算框架 …</pre></div></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/15da-shu-ju-yu-mapreduce.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/16tui-jian-xi-tong.html">16.推荐系统</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第16章 推荐系统</h1>
<h2>背景与挖掘目标</h2>
<p>随着互联网的快速发展，用户很难快速从海量信息中寻找到自己感兴趣的信息。因此诞生了：搜索引擎+推荐系统</p>
<p>本章节-推荐系统：</p>
<ol>
<li>帮助用户发现其感兴趣和可能感兴趣的信息。</li>
<li>让网站价值信息脱颖而出，得到广大用户的认可。</li>
<li>提高用户对网站的忠诚度和关注度，建立稳固用户群体。</li>
</ol>
<h2>分析方法与过程</h2>
<p>本案例的目标是对用户进行推荐，即以一定的方式将用户与物品（本次指网页）之间建立联系。</p>
<p>由于用户访问网站的数据记录很多，如果不对数据进行分类处理，对所有的记录直接采用推荐系统进行推荐，这样会存在一下问题。</p>
<ol>
<li>数据量太大意味着物品数与用户数很多，在模型构建用户与物品稀疏矩阵时，出现设备内存空间不够的情况，并且模型计算需要消耗大量的时间。</li>
<li>用户区别很大，不同的用户关注的信息不一样，因此 …</li></ol></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/16tui-jian-xi-tong.html">Read On &crarr;</a>
  </footer>
  		</article>
  		<article>
<header>
      <h1 class="entry-title">
        <a href="./pages/2017/01/1ji-qi-xue-xi-ji-chu.html">1.机器学习基础</a>
      </h1>
    <p class="meta">
<time datetime="2017-01-01T00:00:00+08:00" pubdate>2017-01-01 00:00</time>    </p>
</header>

  <div class="entry-content"><h1>第1章 机器学习基础</h1>
<h2>机器学习 概述</h2>
<p><code>机器学习(Machine Learning,ML)</code> 是使用计算机来彰显数据背后的真实含义，它为了把无序的数据转换成有用的信息。是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。
它是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域，它主要使用归纳、综合而不是演绎。</p>
<ol>
<li>海量的数据</li>
<li>获取有用的信息</li>
</ol>
<h2>机器学习 研究意义</h2>
<p>机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能 …</p></div>
  <footer>
    <a rel="full-article" href="./pages/2017/01/1ji-qi-xue-xi-ji-chu.html">Read On &crarr;</a>
  </footer>
  		</article>
<div class="pagination">
    <a class="prev" href="./index9.html">&larr; Older</a>

    <a class="next" href="./index7.html">Newer &rarr;</a>
  <br />
</div></div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="./pages/2019/01/tf-example-0101-helloworld.html">tf-example-01.01-helloworld</a>
      </li>
      <li class="post">
          <a href="./pages/2019/01/tf-example-0102-basic-eager-api.html">tf-example-01.02-basic-eager-api</a>
      </li>
      <li class="post">
          <a href="./pages/2019/01/tf-example-0103-basic-operations.html">tf-example-01.03-basic-operations</a>
      </li>
      <li class="post">
          <a href="./pages/2019/01/tf-example-0201-linear_regression_eager_api.html">tf-example-02.01-linear_regression_eager_api</a>
      </li>
      <li class="post">
          <a href="./pages/2019/01/tf-example-0202-linear_regression.html">tf-example-02.02-linear_regression</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="./category/01chang-yong-gong-ju.html">01常用工具</a></li>
        <li><a href="./category/02wo-ai-du-shu.html">02.我爱读书</a></li>
        <li><a href="./category/book-pydata.html">book-pydata</a></li>
        <li><a href="./category/ji-chu-zhi-shi.html">基础知识</a></li>
        <li><a href="./category/ji-qi-xue-xi-shi-zhan.html">机器学习实战</a></li>
        <li><a href="./category/ling-ji-chu-ru-men-shen-du-xue-xi.html">零基础入门深度学习</a></li>
        <li><a href="./category/shen-du-xue-xi.html">深度学习</a></li>
        <li><a href="./category/tf-example.html">tf-example</a></li>
        <li><a href="./category/tools.html">tools</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="./tag/python.html">python</a>,    <a href="./tag/numpy.html">numpy</a>,    <a href="./tag/tf-example.html">tf-example</a>,    <a href="./tag/mapreduce.html">mapreduce</a>,    <a href="./tag/net.html">net</a>,    <a href="./tag/spark.html">spark</a>,    <a href="./tag/sun-shi-han-shu.html">损失函数</a>,    <a href="./tag/tf.html">tf</a>,    <a href="./tag/ji-huo-han-shu.html">激活函数</a>,    <a href="./tag/handbook.html">handbook</a>,    <a href="./tag/matplotlib.html">matplotlib</a>,    <a href="./tag/scikit-learn.html">scikit-learn</a>,    <a href="./tag/latex.html">latex</a>,    <a href="./tag/pandas.html">pandas</a>,    <a href="./tag/jupyter.html">jupyter</a>,    <a href="./tag/plot.html">plot</a>,    <a href="./tag/pip.html">pip</a>,    <a href="./tag/geng-xin-suo-you-mo-kuai.html">更新所有模块</a>,    <a href="./tag/shen-du-xue-xi.html">深度学习</a>,    <a href="./tag/xun-huan-shen-jing-wang-luo.html">循环神经网络</a>,    <a href="./tag/pangrank.html">PangRank</a>,    <a href="./tag/book.html">book</a>,    <a href="./tag/pydata.html">pydata</a>,    <a href="./tag/shell.html">shell</a>,    <a href="./tag/pyhton.html">pyhton</a>,    <a href="./tag/xgboost.html">xgboost</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="#" target="_blank">You can add links in your config file</a></li>
            <li><a href="#" target="_blank">Another social link</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://getpelican.com/" target="_blank">pelican</a></li>
            <li><a href="http://python.org/" target="_blank">python</a></li>
            <li><a href="#" target="_blank">You can modify those links in your config file</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
        活到老，学到老，玩到老
    <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="./theme/js/modernizr-2.0.js"></script>
  <script src="./theme/js/ender.js"></script>
  <script src="./theme/js/octopress.js" type="text/javascript"></script>
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-132396898-1', 'auto');

    ga('require', 'displayfeatures');
    ga('send', 'pageview');
    </script>
</body>
</html>